import os
import torch
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, random_split

def create_dataloaders(data_dir, batch_size=32, img_size=224, split_ratio=(0.8, 0.1, 0.1)):
    """
    ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ìš© DataLoaderë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        data_dir (str): ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬. 
                        ì´ ë””ë ‰í„°ë¦¬ ë‚´ì— 'train' ë˜ëŠ” ìœ ì‚¬í•œ í´ë”ê°€ ìˆê³ ,
                        ê·¸ ì•ˆì— 'real', 'fake' ë“±ì˜ í´ë˜ìŠ¤ í´ë”ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
                        Kaggle ë…¸íŠ¸ë¶ì—ì„œëŠ” '/kaggle/input/...' ê²½ë¡œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        batch_size (int): í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ì˜ ìˆ˜.
        img_size (int): ëª¨ë¸ì— ì…ë ¥ë  ì´ë¯¸ì§€ì˜ í¬ê¸°.
        split_ratio (tuple): (train, val, test) ë¹„ìœ¨. ê¸°ë³¸ê°’ (0.8, 0.1, 0.1)

    Returns:
        tuple: (train_loader, val_loader, test_loader, class_names)
               í•™ìŠµìš©, ê²€ì¦ìš©, í…ŒìŠ¤íŠ¸ìš© DataLoader, í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸.
    """
    # Kaggle ë…¸íŠ¸ë¶ í™˜ê²½ ê°ì§€
    is_kaggle = os.path.exists("/kaggle/input")
    if is_kaggle and not os.path.exists(data_dir):
        # Kaggleì—ì„œ ìë™ìœ¼ë¡œ ë°ì´í„° ê²½ë¡œ ì°¾ê¸° ì‹œë„
        kaggle_input = "/kaggle/input"
        possible_paths = [
            os.path.join(kaggle_input, "realifake", "Realifake"),
            os.path.join(kaggle_input, "realifake", "train"),
            os.path.join(kaggle_input, "realifake"),
            data_dir  # ì›ë˜ ê²½ë¡œë„ ì‹œë„
        ]
        for path in possible_paths:
            if os.path.exists(path):
                print(f"ğŸ” Kaggle ë…¸íŠ¸ë¶: ë°ì´í„° ê²½ë¡œ ìë™ ê°ì§€ -> {path}")
                data_dir = path
                break
    
    # ì‹œë“œ ê³ ì • (ì¬í˜„ì„±ì„ ìœ„í•´)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    data_transforms = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”
    ])

    # ë°ì´í„°ì…‹ ë¡œë“œ
    try:
        full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)
        class_names = full_dataset.classes
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ. í´ë˜ìŠ¤: {class_names}")
        print(f"ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}")
        
        if len(full_dataset) == 0:
            print("âŒ ê²½ê³ : ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            return None, None, None, None
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: '{data_dir}' ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        if is_kaggle:
            print("\nğŸ“Œ Kaggle ë…¸íŠ¸ë¶ ì‚¬ìš© ì‹œ:")
            print("   1. ë°ì´í„°ì…‹ì„ 'Add Data' ë²„íŠ¼ìœ¼ë¡œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("   2. ë°ì´í„° ê²½ë¡œê°€ '/kaggle/input/ë°ì´í„°ì…‹ì´ë¦„/train' í˜•ì‹ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("   3. config.yamlì˜ train_dirì„ ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”")
        else:
            print("   Kaggle ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ 'data' í´ë”ì— ì••ì¶•ì„ í’€ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print("   ë°ì´í„°ì…‹ êµ¬ì¡° ì˜ˆì‹œ: 'data/train/real', 'data/train/fake'")
        return None, None, None, None
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None, None

    # ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í•  (8:1:1)
    total_size = len(full_dataset)
    train_size = int(split_ratio[0] * total_size)
    val_size = int(split_ratio[1] * total_size)
    test_size = total_size - train_size - val_size  # ë‚¨ì€ ê±° ì „ë¶€
    
    train_dataset, val_dataset, test_dataset = random_split(
        full_dataset, [train_size, val_size, test_size]
    )

    print(f"ë¶„í•  ì™„ë£Œ -> Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}")

    # DataLoader ìƒì„±
    # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] num_workersë¥¼ 2ë¡œ ê³ ì • (ì†ë„ ìµœì í™”)
    max_workers = 2
    print(f"ğŸš€ ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜: {max_workers} (ì†ë„ ìµœì í™”)")
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                              num_workers=max_workers, pin_memory=True if torch.cuda.is_available() else False)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=max_workers, pin_memory=True if torch.cuda.is_available() else False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, 
                            num_workers=max_workers, pin_memory=True if torch.cuda.is_available() else False)

    return train_loader, val_loader, test_loader, class_names

if __name__ == '__main__':
    # --- ì„¤ì • ---
    # ë°ì´í„°ì…‹ì´ ì €ì¥ëœ ê¸°ë³¸ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
    # CIFAKE ë°ì´í„°ì…‹ì˜ ê²½ìš° 'train' í´ë”ë¥¼ ì§€ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì˜ˆ: 'data/CIFAKE/train'
    DATA_PATH = "data/" 
    BATCH_SIZE = 64

    # --- ì‹¤í–‰ ---
    train_dataloader, val_dataloader, test_dataloader, classes = create_dataloaders(data_dir=DATA_PATH, batch_size=BATCH_SIZE)

    # --- í…ŒìŠ¤íŠ¸ ---
    # DataLoaderê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€, ë°ì´í„° í•œ ë°°ì¹˜ë¥¼ ë½‘ì•„ì„œ í™•ì¸
    if train_dataloader:
        print("\n--- DataLoader í…ŒìŠ¤íŠ¸ ---")
        # next(iter(...))ë¥¼ í†µí•´ ë°ì´í„°ë¡œë”ì—ì„œ ì²« ë²ˆì§¸ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜´
        images, labels = next(iter(train_dataloader))

        print(f"ì´ë¯¸ì§€ ë°°ì¹˜ í˜•íƒœ: {images.shape}")
        print(f"ë¼ë²¨ ë°°ì¹˜ í˜•íƒœ: {labels.shape}")
        print(f"í´ë˜ìŠ¤: {classes}")
        print(f"ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ë¼ë²¨: {labels}")
        # ë¼ë²¨ 0: classes[0], ë¼ë²¨ 1: classes[1] ì— í•´ë‹¹
